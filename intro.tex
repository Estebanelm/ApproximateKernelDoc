%% ---------------------------------------------------------------------------
%% intro.tex
%%
%% Introduction
%%
%% $Id: intro.tex 1477 2010-07-28 21:34:43Z palvarado $
%% ---------------------------------------------------------------------------

\chapter{Introduction}
\label{chp:intro}

Computers were invented to accelerate manually created processes. In the beginning, computers
offered speeds far superior than what a human could manage on specific activities, but their use
was limited to relatively low data processing. 

Throughout the era of increasingly advanced semiconductor technologies, a need for using computers 
with applications for high level processing has risen, along with higher amount of data to process.
This has generated a race for maintaining a high performance level along with equal or even reduced 
energy, time and storage consumption. The main solution, for some years now, has been to increase the 
computing power of the computers via mechanisms such as, for example, increasing the amount of transistors
per area. This solution, however, has brought with it a lot of considerations and problems, specially 
regarding energy consumption.

A new approach has surfaced as one of the solutions to the energy consumption problem is, approximate computing.
This computing paradigm was born on the assumption that there are cases on which an exact result, with high precision,
is not needed. A lot of data come from inexact (sensors, readings) or do not require a precise processing
algorithm (machine learning, user recommendation programs, statistics). This type of applications are
known as error-tolerant. Approximate computing looks to use these types of data to create algorithms,
languages, compilers, circuits and computer architectures that have the common objective of lowering
the energy consumption and increasing the performance at the cost of having an approximate result.

One of the most important areas of research currently is machine learning. Its main property is
decision making based on processing big amounts of data. This data can be written, visual (images, video) or 
audio information, as well as taking the feedback into account to improve the learning process.
Approximate computing can take advantage of this fact and use it to reduce the computational effort
required and, in this manner, improve significantly the investigation area of machine learning.

This work looks to explore methods and techniques for aproximate hardware definition on FPGA, such that
it could be used on machine learning applications, specifically by generating approximate hardware
kernels for CNNs through the use of OpenCL. The current project will deliver useful tools for any 
other developer that requires to accelerate their machine learning algorithms through the use of FPGAs.

\section{Project background}

\subsection{Organization}

The project is developed in the KIT, an university focused on the development of technology and science.
KIT was created on 2009 after the convergence of the University of Karlsruhe, funded on 1825, and the 
Investigation Center of Karlsruhe. It is located in Karlsruhe, in the Baden-Württemberg state, to the
southwest of Germany. Figure 1 shows a map with the location of Baden-Württemberg inside the european
country and the location of Karlsruhe inside the aforementioned state.

Nowadays, KIT is one of the most prestiogious technical universities in Germany, specialized on engineering
and science. Figure 2 shows the current logo of the university. KIT is conformed by a scientific organization
separated by divisions:

\begin{compactitem}
    \item Division I: Biology, Chemistry and Process Engineering.
    \item Division II: Informatics, Economy and Society.
    \item Division III: Mechanical and Electrical Engineering.
    \item Division IV: Natural and Built Environment.
    \item Division V: Physics and Mathematics.
\end{compactitem}

These divisions are constituted by departments destined to investigational work, innovation and teaching.
Each department has institutes responsible for university education. Aside from the institutes, there are
KIT centers, on which topics related to investigation and innovation go beyond the divisions, supporting
an interdisciplinary cooperation. 


The Department of Informatics is one of the first to be established on Germany. This department is formed
by different institutes focused on teaching and investigation of topics associated with informatics. As
part of the Department of Informations the CES comes as a center of investigation on aspects related
with the design of embedded systems, from the reliability of electrical circuits to the management of
electrical power on systems with multiple and many cores.

\subsection{Knowledge area}

The project is developed within the technical area of approximate computing, which is part of the areas
of interest of computer engineering. Approximate computing looks to relax the numerical equivalence 
between the specification and implementation of such applications, approximate computing promises significant 
energy-efficiency improvements and has gained significant traction over the past few years [2]. Within
appromate computing, the project focuses on the utilization of \intelOCL to develop approximate hardware
kernels and their application on CNNs, highlighting the effect of these kernels on the improvement in 
performance and reduction on energy consumption in comparison to exact kernels.

Furthermore, OpenCL is a tool that allows to define procedures on heterogeneous platformes through the 
use of a high-level programming language. The knowledge on hardware changes via the use of a software 
description is necessary to develop the project.

\subsection{Similar works}

Esto es relleno para poner las secciones de la introduccion.

\section{Problem statement}

\subsection{Problem context}

In the last years, discussions on the physical (and economical) limits of the very large scale integration 
of transistors have surfaced [4][5], where statements like Moore's Law exert pressure the big chip manufaturers.
Gordon Moore himself has assured that this trend cannot be maintained for a long time [6]. This leads to the
search of new paradigms or techniques that allow to sustatin the high requirements on performance and 
energy consumption of applications in the technological world, where a need to process even higher amounts
of data is increasing. Some solutions to this increasing demand have appeared, such as multicore computers,
multithreading architectures, large scale computers, GPU processing and more.

Despite these solutions, there exist other problems that cannot be solved just by improving on the architecture
of the processor. Some of these problems are:

\begin{compactitem}
    \item The memory wall: Wulf and McKee[7] describe an inminent problem on which the superior speed increase
    of the processors is a lot higher that the improvement on memory technologies. This requires solutions that
    try to reduce the amount of memory accesses.
    \item The utilization wall: Taylor et al.[8] noticed a phenomenom that appears due to the increase on the amount
    of transistors per unit of area in a chip. The problem is related to an exponential reduction of the usable
    percentage of the chip depending on the scale of integration of the transistors.
    \item Problems with thermal dissipation: with the increase of frequency of the microprocessors, the level of 
    heat disipation has increased, forcing a reduction on the operational voltage. Some solutions have been proposed
    to this problem, like the utilization of multicore processorss with cores that deactivate themselves to reduce
    the workload [9].
\end{compactitem}

Due to these problems and the increasing existence of error-resilient applications (e.g. [10]) paradigms such as
approximate computing have appeared. This paradigm tries to eliminate, or reduce, the need for precision
during processing with the goal of obtaining gains in energy efficiency and processing speed.

Furthermore, one area of interest withing the error-resilient application world is machine learning.
The goal of this area is to allow a computational system to execute tasks without the need for a prior
specific programming and, in some cases, using previous results as feedback to improve the execution.
Algorithms used in machine learning look to build mathematical models based on "training" data to perform
tasks without explicit programming [11]. Due to their nature, machine learning applications do not present
an exact response inmediately, or even never, instead they require multiple feedback cycles to achieve
the expected response. This means that approximate computing is a potential paradigm to work with this
type of applications [12].

\subsection{Justification of the problem}

La computación aproximada es un área que se encuentra en un período de auge. Existen diversas
investigaciones y diseños que buscan aprovechar la existencia de aplicaciones tolerantes a errores. Sin
embargo, es necesario continuar avanzando el paradigma para poder observar sus aportes en el día a
día. La importancia de este paradigma reside en que no depende del estado actual de la tecnología para
brindar mejoras energéticas y de rendimiento.

El uso de FPGA en el área de computación aproximada se encuentra poco explorado y aplicaciones en
lenguaje de máquina son de interés global. Una mejora significativa en estos dos campos (y su
combinación) generaría nuevas posibilidades para la exploración de soluciones con bajo consumo
energético y alto nivel de adaptabilidad.Así, este proyecto es importante por varias razones:

\begin{compactitem}
    \item Permite avanzar la investigación en el área de definición de hardware aproximado utilizando
herramientas populares como OpenCL, lo cual puede servir de base para próximas
investigaciones con aplicaciones basadas en FPGA. 
    \item El uso de una herramienta popular permite agilizar el proceso de generación de resultados en un área poco explorada.
    \item Genera herramientas listas para ser utilizadas en aplicaciones de aprendizaje de máquina
basadas en redes neuronales. Estas pueden ser kernels o conjuntos de kernels customizables.
Cualquier interesado que quiera realizar procesamiento y tenga un margen de error tolerable
debería ser capaz de utilizar los resultados del proyecto.
\end{compactitem}



\subsection{Problem definition}

Las aplicaciones de aprendizaje de máquina se basan en distintos métodos para obtener resultados. Una
de las técnicas más utilizadas son las redes neuronales (neural networks) cuyo objetivo es imitar el
trabajo que realiza el cerebro humano para obtener resultados. Además, existe una rama dentro del
aprendizaje de máquina conocida como aprendizaje profundo (deep learning). Esta consiste en el
aumento en la cantidad de capas de aprendizaje en las redes neuronales para obtener una mayor
cantidad de detalles a partir de una entrada de datos [13]. Las capas están representadas por nodos
(neuronas) que realizan procesamiento sobre la entrada. Este proceso requiere de un alto nivel de
procesamiento, pero sus resultados son en su mayoría aproximaciones.

Además, las field-programmable gate array (FPGA, por sus siglas en inglés) son dispositivos que
recientemente han sido el objeto de investigaciones con el objetivo de acelerar el procesamiento
realizado. Esto debido a que los CPU de uso general no ofrecen la capacidad de procesamiento
suficiente (operaciones múltiples con alto nivel de complejidad al mismo tiempo) y los GPU, a pesar de
tener capacidades de procesamiento sobre múltiples datos, no son por completo especializados o
customizables. El uso de un dispositivo que puede ser programado para tareas específicas (en este caso,
redes neuronales) ofrece posibilidades de procesamiento que superan aún a los GPU [14].

De esta manera, el proyecto surge con el objetivo de aportar a la investigación en el área de FPGAs para
uso en aplicaciones de aprendizaje de máquina por medio de definición de hardware aproximado. Cada
neurona en una red neuronal es representada por medio de un “kernel” de hardware, que define por sí
mismo los cálculos y procesos que debe realizar cada una de las neuronas. Por medio de herramientas
de software como OpenCL, es posible definir kernels para realizar tareas de aprendizaje de máquina.
Así, combinando todas estas áreas y herramientas, se espera lograr mejoras en rendimiento y en
consumo energético necesarios para suplir la demanda de procesamiento actual.

\section{Objectives}

\subsection{Main objective}

Design an approximate hardware implementation of CNNs through the 
use of \intelOCL.

\subsection{Specific objectives}

\begin{compactitem}
    \item Describe the viable changes on the OpenCL tool for approximate hardware generation on FPGA.
    \item Create aproximate and reusable hardware kernels for CNNs using OpenCL.
    \item Determine the error-tolerance level of CNNs when using approximate kernels instead of exact kernels.
    \item Ascertain the reduccion of computational resources when using approximate kernels compared to the use of traditional exact kernels.
\end{compactitem}

\section{Scope, deliverables and limitations}

\subsection{Scope}


\subsection{Deliverables}

En la figura 4 se pueden se observa un diagrama con los entregables del proyecto.

1. Investigación teórica

1.1. Informe recopilatorio de uso de redes neuronales en FPGA: este informe contendrá toda
la información relevante para ser utilizada en el resto del proyecto y que permita tomar
decisiones en cuanto a redes neuronales en FPGA.

1.2. Informe de avance con las modificaciones realizables: informe con las posibilidades de
modificación en la herramienta OpenCL y que afecten la definición de hardware en
FPGA.

2. Etapa de diseño

2.1. Documentación de método para aproximar redes neuronales: recopila la información
necesaria sobre los principios de computación aproximada que son aplicables en redes
neuronales, específicamente para algoritmos de aprendizaje profundo. Debe contener
modelos matemáticos que puedan ser comparados contra los resultados del proyecto.

2.2. Diseño del modelo de cálculos de error: contiene la formulación matemática que
permite realizar un cálculo de la precisión de los resultados que se van a obtener y los
compare con la ganancia de rendimiento.2.3.

2.3. Diseño de una aplicación de prueba: es un documento con el diseño general de una
aplicación que será utilizara para realizar las pruebas prácticas una vez se haya
desarrollado el proyecto.


3. Desarrollo de código

3.1. Código fuente: código fuente de la aplicación en OpenCL y cualquier otro código
necesario para realizar las pruebas prácticas.

3.2. Kernels exactos: código fuente de los kernels exactos que se utilizarán para realizar las
pruebas.

3.3. Kernels aproximados: código fuente de los kernels aproximados que se utilizarán para
realizar las pruebas.

4. Pruebas

4.1. Resultados de las pruebas exactas: mediciones de rendimiento y precisión al realizar
pruebas sobre kernels exactos.

4.2. Resultados de las pruebas aproximadas: mediciones de rendimiento y precisión al
realizar pruebas sobre kernels aproximadas.

4.3. Documentación de resultados: comparación de los resultados obtenidos entre las
pruebas exactas y aproximadas.

5. Gestión del proyecto

5.1. Documento de diseño: diseño de todas las herramientas desarrolladas durante el
proyecto.

5.2. Minutas de reuniones: contiene toda la información que se obtenga de las reuniones de
avance y validación.

5.3. Informe de trabajo final: informe final del trabajo final de graduación con toda la
información relevante que se generó en el proyecto.

\subsection{Limitations}

LIM-01: ​ el estudiante puede movilizarse a Alemania hasta el primero de Agosto debido a trámites de
visa europea.

LIM-02:​ el presupuesto del estudiante es de 1000 euros mensuales durante la estadía en Alemania.

LIM-03: el estudiante está atado a las regulaciones y limitaciones de la universidad KIT con los
estudiantes internacionales.

LIM-04: no hay posibilidad de realizar reuniones presenciales con el profesor asesor del proyecto debido a
la localización del estudiante durante el proyecto. Toda reunión o comunicación se realizará de manera
remota.

% \subsection{Risks}

% RIE-01: ​ Recibir un rechazo de la solicitud de la visa. El proceso de solicitud de visa ya fue iniciado, pero
% existen diversos factores que pueden hacer que la visa sea rechazada y que están fuera del control del
% estudiante.
% - Probabilidad: media. Existe un antecedente de la extensión de solicitud de visa por parte de otro
% estudiante que realizó el mismo viaje hacia Alemania.
% - Impacto: medio. El no tener visa significa que el tiempo de estadía en Alemania se reduce a 3
% meses. El tiempo no se reduce demasiado, pero eso añade una presión extra al estudiante y
% reduce el tiempo efectivo de desarrollo del proyecto.
% - Acciones mitigadoras: se va a iniciar el proyecto con la sección de investigación un tiempo antes
% del viaje hacia Alemania para reducir el impacto de una reducción del tiempo de estadía.

% RIE-02: No conseguir un lugar de residencia para la fecha de llegada a Alemania. Los procesos de
% obtención de residencia en Alemania contienen diversos pasos, entre ellos una entrevista personal que
% supone una mayor dificultad para obtener un lugar de estadía.
% - Probabilidad: baja. A pesar de que cada lugar tiene diferentes procesos, existen muchas
% opciones de estadía y el precio de alquiler no supone un riesgo para el proyecto. Además,
% existen opciones para alojarse mientras se busca una estadía permanente.
% - Impacto: bajo. De no encontrar un hospedaje para la fecha de llegada, el estudiante deberá
% disponer de tiempo de desarrollo del proyecto para conseguir el hospedaje.
% - Acciones mitigadoras: el estudiante debe agotar todas las opciones existentes de hospedaje
% meses antes del viaje a Alemania para aumentar las posibilidades de conseguir alojamiento.

% RIE-03: El estudiante deberá obtener un vuelo que se adapte a las necesidades de fecha de inicio de las
% tareas en Alemania y a las limitaciones de tiempo impuestas por la visa (o falta de ella). Debido a que los
% vuelos suponen un complejo sistema de escalas y destinos, existe un riesgo de obtener un vuelo que
% llegue a Alemania en una fecha posterior a la prevista.
% - Probabilidad: baja. Existen múltiples opciones para conseguir vuelos que se adapten a las
% diferentes necesidades de las personas.
% - Impacto: baja. El proyecto se podría retrasar varios días.
% - Acciones mitigadoras: se debe obtener un vuelo que satisfaga las necesidades del estudiante
% con anticipación y estar atento a nuevas opciones.

% RIE-04: La universidad KIT permite a todo estudiante admitido ser registrado en ella. Esto ofrece
% beneficios específicos para estudiantes matriculados en universidades alemanas, como descuentos en
% transporte público. El riesgo está en que el registro no pueda ser completado.
% - Probabilidad: baja. El estudiante ya fue admitido en la universidad y el cumplir con todos los
% requisitos reduce la posibilidad de que el registro sea rechazado.
% - Impacto: baja. El no ser registrado podría provocar un aumento en los gastos financieros del
% estudiante,. Sin embargo, esto no supone mayor inconveniente.-
% Acciones mitigadoras: el estudiante ha ahorrado dinero extra en caso de necesitar realizar
% gastos mayores de los esperados.

% RIE-05: El proyecto depende de que la herramienta de software permita modificaciones adecuadas para
% la definición de hardware aproximado en FPGA. Un riesgo del proyecto es que la herramienta no
% permita realizar definición de hardware no exacto.
% - Probabilidad: media. La herramienta a utilizar es Intel® FPGA SDK for OpenCLTM. Este es un
% framework de código-cerrado.
% - Impacto: medio. De no ser capaz de utilizar OpenCL para desarrollar el proyecto, se deberá
% acudir a otras opciones, esto retrasaría el proyecto.
% - Acciones mitigadoras: el estudiante deberá buscar otras opciones antes de iniciar el proyecto
% para evitar un bloqueo en el proyecto.

% RIE-06: De ser capaz de realizar modificaciones en la definición de hardware obtenida por parte de la
% herramienta, existe el riesgo de que estas modificaciones no sean suficientes para obtener hardware
% aproximado para kernels de redes neuronales.
% - Probabilidad: media. Esta es una de las mayores incertidumbres del proyecto y parte de los
% resultados de la investigación teórica.
% - Impacto: alto. El no ser capaz de realizar modificaciones para obtener hardware aproximado
% significa un replanteamiento por completo del proyecto.
% - Acciones mitigadoras: la primera tarea que debe realizar el estudiante es investigar las
% diferentes modificaciones que se deben realizar para reducir la incertidumbre del proyecto.

% RIE-07: Con la suposición de que es posible aproximar el hardware generado por la herramienta de
% software, aparece el riesgo de que la aproximación realizada en redes neuronales no permita tener un
% error suficientemente aceptable en los resultados prácticos de los algoritmos de aprendizaje.
% - Probabilidad: baja. Existen diversos estudios que tratan el tema de aproximación de redes
% neuronales.
% - Impacto: medio. Aunque no se obtenga un resultado positivo en algoritmos de aprendizaje, el
% proyecto puede tener resultados que permitan potenciar otras investigaciones.
% - Acciones mitigadoras: el estudiante deberá mantenerse informado con respecto a las
% posibilidades de mejora en redes neuronales así como los niveles de error que pueden ser
% considerados como aceptables.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
